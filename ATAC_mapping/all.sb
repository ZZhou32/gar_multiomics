#!/bin/bash --login

# Number of nodes
#SBATCH --nodes=8

# Number of tasks to run on each node
#SBATCH --ntasks-per-node=6

# Number of CPUs per task
#SBATCH --cpus-per-task=4

# Memory per Node
# Specify "M" or "G" for MB and GB respectively
#SBATCH --mem=8G

# Wall time
# Format: "minutes", "hours:minutes:seconds", 
# "days-hours", or "days-hours:minutes"
#SBATCH --time=03:00:00

# Mail type
# e.g., which events trigger email notifications
#SBATCH --mail-type=ALL

# Mail address
#SBATCH --mail-user=zhouzeh2@msu.edu

# Standard output and error to file
# %x: job name, %j: job ID
#SBATCH --output=/mnt/research/FishEvoDevoGeno/raw_reads_4_tony/RNA_qc/out/%x-%j.SLURMout

echo "This script to index genome with Bowtie2."
## module spider bowtie2
# Purge current modules and load those we require
module purge
module load Bowtie2/2.4.5-GCC-11.3.0


# Run our job
cd /mnt/research/FishEvoDevoGeno/raw_reads_4_tony

bowtie2-build GCF_040954835.1_fLepOcu1.hap2_genomic.fna /mnt/research/FishEvoDevoGeno/raw_reads_4_tony/indexed_genome/hardmaskedgar 




#!/bin/bash --login

# Number of nodes
#SBATCH --nodes=8

# Number of tasks to run on each node
#SBATCH --ntasks-per-node=6

# Number of CPUs per task
#SBATCH --cpus-per-task=4

# Memory per Node
# Specify "M" or "G" for MB and GB respectively
#SBATCH --mem=8G

# Wall time
# Format: "minutes", "hours:minutes:seconds", 
# "days-hours", or "days-hours:minutes"
#SBATCH --time=03:00:00

# Mail type
# e.g., which events trigger email notifications
#SBATCH --mail-type=ALL

# Mail address
#SBATCH --mail-user=zhouzeh2@msu.edu

# Standard output and error to file
# %x: job name, %j: job ID
#SBATCH --output=/mnt/research/FishEvoDevoGeno/raw_reads_4_tony/RNA_qc/out/%x-%j.SLURMout

echo "This script to index genome with Bowtie2."
## module spider bowtie2
# Purge current modules and load those we require
module purge
module load Bowtie2/2.4.5-GCC-11.3.0
module load SAMtools/1.9

# Run our job
cd /mnt/research/FishEvoDevoGeno/raw_reads_4_tony
#index genome
bowtie2-build GCF_040954835.1_fLepOcu1.hap2_genomic.fna /mnt/research/FishEvoDevoGeno/raw_reads_4_tony/index_genome/fLepOcu1hap2

#####  index masked genome
#####  map all ATAC reads and convert and sort bam
for sample in `ls /mnt/research/FishEvoDevoGeno/raw_reads_4_tony/ATAC_qc/*_R1clean.fq`
do
dir="/mnt/research/FishEvoDevoGeno/raw_reads_4_tony/ATAC_qc"
output_dir="/mnt/research/FishEvoDevoGeno/raw_reads_4_tony/ATAC_bam"
base=$(basename $sample "_R1clean.fq")

bowtie2 --very-sensitive -x /mnt/research/FishEvoDevoGeno/raw_reads_4_tony/index_genome -1 ${dir}/${base}_R1clean.fq -2 ${dir}/${base}_R2clean.fq | samtools view -u | samtools sort >> ${output_dir}/${base}_sorted.bam
done

#####   remove non-uniquely-mapped reads from all ATAC reads

samtools view -b  -q 10  F{}_sorted_no_mito_no_dup.bam  >  F{}_sorted_no_mito_no_dup_uniq.bam
# index filtered bam files for ATAC reads
parallel 'samtools index {}' ::: *_sorted_no_mito_no_dup_uniq.bam


# You MUST specify the number of CPUs per task again.
# Alternatively, you can set OMP_NUM_THREADS
srun -c $SLURM_CPUS_PER_TASK script/

# Print resource information
scontrol show job $SLURM_JOB_ID
js -j $SLURM_JOB_ID 

